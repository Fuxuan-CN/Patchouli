
import torch
from torch import nn
from torch.utils.data import DataLoader
from pathlib import Path
from typing import Optional
from ..schemas.train_method import TrainMethod
from ..utils.logger import logger
from ..knowledge import CharDataset
from ..brain.tokenizer import PatchouliTokenizer as DefaultTokenizer
from ..schemas.type_hints import ValidatorProtocol, TokenizerProtocol

class Trainer:
    """ æ¨¡å‹è®­ç»ƒå™¨ """

    def __init__(self, 
        cfg: TrainMethod, 
        model: nn.Module, 
        tokenizer: TokenizerProtocol = DefaultTokenizer(), 
        brain_validator: Optional[ValidatorProtocol] = None
    ) -> None:
        logger.debug(f"åˆå§‹åŒ–è®­ç»ƒå™¨...")
        self.validator = brain_validator
        """ éªŒè¯å™¨ """
        self.cfg = cfg
        """ è®­ç»ƒå™¨é…ç½® """
        self.use_cuda = self.cfg.device.startswith("cuda")
        """ æ˜¯å¦ä½¿ç”¨æ˜¾å¡ """
        self.device = self._resolve_device()
        """ è®­ç»ƒç”¨çš„è®¾å¤‡ """
        logger.debug(f"ä½¿ç”¨çš„è®¾å¤‡: {self.device}")
        self.tokenizer = tokenizer
        """ åˆ†è¯å™¨ """
        logger.debug(f"æ¨¡å‹: {model.__class__.__name__} è½½å…¥è®¾å¤‡")
        self.model = model.to(self.device)
        """ è®­ç»ƒçš„æ¨¡å‹ """
        logger.debug("è½½å…¥å®Œæˆï¼Œå¼€å§‹è®­ç»ƒé˜¶æ®µ...")
        if not self.validator:
            logger.info("brain_validatorä¸ºç©º, æ²¡æœ‰æ¨¡å‹éªŒè¯å™¨, åç»­è®­ç»ƒå°†é™¤å¼€éªŒè¯æµç¨‹...")
        if self.use_cuda:
            cuda_mem_used = torch.cuda.memory_allocated(self.device) / 1024**3
            logger.success(f"æ¨¡å‹: {self.model.__class__.__name__} è½½å…¥å®Œæˆï¼Œè½½å…¥ä½¿ç”¨çš„æ˜¾å­˜: {cuda_mem_used} GB")

    # ---------------- å†…éƒ¨å·¥å…· ----------------
    def _resolve_device(self) -> str:
        if self.cfg.device == "auto":
            return "cuda" if torch.cuda.is_available() else "cpu"
        
        if self.cfg.device == "cuda" and not torch.cuda.is_available():
            logger.warning("æŒ‡å®š CUDA ä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU | å¯èƒ½å‘ç”Ÿæ½œåœ¨çš„æ€§èƒ½ä¸‹é™...")
            return "cpu"

        return self.cfg.device
    
    def _validate(self, epoch: int) -> None:
        """ éªŒè¯æ¨¡å‹ï¼Œå¦‚æœæœ‰æ¨¡å‹éªŒè¯å™¨çš„è¯ """
        if self.validator is not None and epoch % self.cfg.val_every == 0:
            logger.info("å¼€å§‹éªŒè¯...")
            val_loss = self.validator(
                self.model, self._build_dataloader(val=True), self.device, epoch
            )
            logger.info(f"éªŒè¯ç»“æœ: epoch {epoch} | val_loss={val_loss:.4f}")

    def _build_dataloader(self, val: bool = False) -> DataLoader:
        """ æ„å»ºæ•°æ®é›†åŠ è½½å™¨ """
        ds = CharDataset(self.cfg.dataset_path, tokenizer=self.tokenizer, block=self.cfg.block) \
        if not val else CharDataset(self.cfg.val_dataset_path, self.tokenizer, self.cfg.block)

        return DataLoader(
            ds,
            batch_size=self.cfg.batch_size,
            shuffle=self.cfg.loader_shuffle,
            num_workers=self.cfg.loader_num_workers,
            pin_memory=self.use_cuda,
        )
    
    def _save_model_epoch(self, epoch: int, optimizer: torch.optim.Optimizer, scaler: torch.GradScaler) -> None:
        """ ä¿å­˜è®­ç»ƒæ¨¡å‹ """
        ckpt = {
            "epoch": epoch,
            "model_state": self.model.state_dict(),
            "optimizer_state": optimizer.state_dict(),
            "scaler_state": scaler.state_dict(),
            # å¦‚æœæœ‰ schedulerï¼Œä¹Ÿå¡è¿›æ¥
        }
        epoch_path = Path(self.cfg.export_model_path).with_suffix(f".epoch{epoch}.pth")
        torch.save(ckpt, epoch_path)
        logger.success(f"ğŸ’¾ å·²ä¿å­˜å®Œæ•´ checkpoint {epoch_path.name}")

    def _save_model_final(self) -> None:
        """ ä¿å­˜æœ€ç»ˆæ¨¡å‹ """
        return torch.save(self.model.state_dict(), self.cfg.export_model_path)

    def _judgment_continue_train(self, _continue: Optional[Path], optimizer: torch.optim.Optimizer, scaler: torch.GradScaler) -> None:
        """ åˆ¤æ–­æ˜¯å¦ç»§ç»­è®­ç»ƒï¼Œå¦‚æœæ˜¯å°†ä¼šåŠ è½½æ¨¡å‹ """
        if _continue and _continue.is_file():
            logger.info(f"ç¡®è®¤äº†ç»§ç»­è®­ç»ƒ, å°†æŒ‡å®šæ¨¡å‹è½½å…¥: {self.device}")
            ckpt = torch.load(_continue, map_location=self.device)
            self.model.load_state_dict(ckpt["model_state"])
            optimizer.load_state_dict(ckpt["optimizer_state"])
            scaler.load_state_dict(ckpt["scaler_state"])
            start_epoch = ckpt["epoch"] + 1
            logger.success(f"ğŸ” è½½å…¥å®Œæˆ, ä¸Šæ¬¡è®­ç»ƒè½®æ•°: {start_epoch - 1}")
    
    def _monitor_system_health(self) -> None:
        """ ç›‘æ§ç³»ç»Ÿå¥åº· """

        if self.use_cuda:
            reserved  = torch.cuda.memory_reserved() / 1024**3
            if reserved > self.cfg.warning_cuda_mem_usage:
                logger.warning(f"æ˜¾å­˜ä½¿ç”¨è¶…è¿‡è­¦æŠ¥é˜ˆå€¼è®¾ç½®: {reserved}GB > {self.cfg.warning_cuda_mem_usage}GB")

    # -------------- ä¸»è®­ç»ƒå…¥å£ --------------
    def start(self, continue_from: Optional[str | Path] = None) -> None:
        """ è®­ç»ƒ """
        _continue = continue_from if isinstance(continue_from, (Path, type(None))) else Path(continue_from)
        dataloader = self._build_dataloader()
        optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=self.cfg.learning_rate,
            weight_decay=0.1,
        )
        scaler = torch.GradScaler(enabled=self.use_cuda)

        start_epoch = 0
        total_tokens = 0
        epochs = 0

        self._judgment_continue_train(_continue, optimizer, scaler)

        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒ, è®­ç»ƒ{self.cfg.epoch}è½®, æ¯è½®{self.cfg.batch_size}æ‰¹æ•°æ®")

        self.model.train()

        try:
            for epoch in range(start_epoch, self.cfg.epoch):
                epoch_loss = 0.0
                epochs = epoch
                for x, role, y in dataloader:
                    x, role, y = x.to(self.device), role.to(self.device), y.to(self.device)

                    with torch.autocast(
                        enabled=self.device.startswith("cuda"),
                        device_type=self.device,
                    ):
                        _, loss = self.model(x, role, y)

                    scaler.scale(loss).backward()
                    scaler.unscale_(optimizer)
                    nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()

                    tokens_in_batch = y.numel()
                    epoch_loss += loss.item() * tokens_in_batch
                    total_tokens += tokens_in_batch

                avg = epoch_loss / max(total_tokens, 1)
                logger.info(f"epoch {epoch} | token avg loss: {avg:.4f}")

                self._validate(epoch)
                # âœ… æ¯ save_every ä¸ª epoch ä¿å­˜ä¸€æ¬¡
                if (epoch + 1) % self.cfg.save_every == 0 or epoch == self.cfg.epoch - 1:
                    self._save_model_epoch(epoch, optimizer, scaler)

                if (epoch + 1) % self.cfg.sys_health_check_every == 0 or epoch == self.cfg.sys_health_check_every - 1:
                    self._monitor_system_health()

        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ç»ˆæ­¢äº†è®­ç»ƒç¨‹åº...")
            if self.cfg.interrupt_save:
                logger.info("æ­£åœ¨ä¿å­˜æ¨¡å‹...")
                self._save_model_epoch(epochs, optimizer, scaler)
        else:
            # è®­ç»ƒå®Œæˆä¼šè¿›å…¥æ­¤å—ä¿å­˜æ¨¡å‹
            logger.info("æ‰€æœ‰è½®æ¬¡è®­ç»ƒå®Œæˆ, å¯¼å‡ºæœ€ç»ˆæƒé‡...")
            self._save_model_final()
            logger.success(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæƒé‡å·²ç»å¯¼å‡ºåˆ°: {self.cfg.export_model_path}")